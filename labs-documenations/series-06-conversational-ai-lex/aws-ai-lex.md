<img src="https://cdn.prod.website-files.com/677c400686e724409a5a7409/6790ad949cf622dc8dcd9fe4_nextwork-logo-leather.svg" alt="NextWork" width="300" />

# Welcome to the Lex Chatbot series!

**Project Link:** [View Project](http://learn.nextwork.org/projects/aws-ai-lex)

**Author:** Roy Piring Jr  
**Email:** rpiringhawaii@gmail.com

---

## I'm Building an AI Chatbot on Amazon Lex!

![Image](http://learn.nextwork.org/refreshed_maroon_timid_jujube/uploads/aws-ai-lex_ba6d42ae)

---

## The Project

This project implements an AI-driven conversational interface using Amazon Lex to handle basic banking inquiries and transactional intents. The system exists to demonstrate how managed NLP services can be used to expose a controlled, text-based interaction layer without building custom language models. The scope is limited to intent recognition, slot filling, and response orchestration rather than end-to-end banking system integration. 

![Image](http://learn.nextwork.org/refreshed_maroon_timid_jujube/uploads/aws-ai-lex_a1b2c3d4)

---

## Hold me accountable!

This section defines a personal time allocation and incentive structure for completing the work. It does not affect the technical design, system behavior, or deployment characteristics of the chatbot and has no impact on runtime configuration, security posture, or operational constraints.

### What is AI in chatbots?

AI-powered chatbots rely on natural language processing to classify user input into intents and extract structured data from unstructured text. Machine learning models support this classification by generalizing from training data rather than relying on static rules. Cloud infrastructure provides the execution environment, scalability boundaries, and managed services required to run these models without direct control of underlying compute resources. Persistent storage systems support conversation state, configuration data, and integration points as needed by the application. 

### How does Amazon Lex simplify chatbot development?

Amazon Lex provides a managed abstraction over speech recognition and natural language understanding, allowing intent models and conversation flows to be defined declaratively. This removes the need to design, train, and host custom NLP pipelines. Integration hooks enable the chatbot to invoke downstream services while Lex manages scaling, availability, and model lifecycle within AWS-defined constraints. The platform is designed to reduce operational overhead rather than maximize model customization

---

## Excited to share my progress - build a chatbot with me!

![Image](http://learn.nextwork.org/refreshed_maroon_timid_jujube/uploads/aws-ai-lex_ba6d42ae)

---
